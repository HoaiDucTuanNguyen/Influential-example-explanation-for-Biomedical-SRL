{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"77ea2ebccf764743b56e2cdcf5459fbc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a3a7d61efb24b74893053710158e7a6","IPY_MODEL_b48a26a20f0441a7adb31d9e3d9ba3c2","IPY_MODEL_7673249f160d4c1c930f12f8d31c2295"],"layout":"IPY_MODEL_e1c6ccdaa6bb4f2eb55b5af7559807ed"}},"7a3a7d61efb24b74893053710158e7a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_faff39882670496d904d1fb3ca512589","placeholder":"​","style":"IPY_MODEL_22310fee17d945578704f491047b4b36","value":"Xử lý Train_GramVar: 100%"}},"b48a26a20f0441a7adb31d9e3d9ba3c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e49b9c5fb9414a22a1c913c246f7b3a5","max":35,"min":0,"orientation":"horizontal","style":"IPY_MODEL_147d2073465b493898d7d8687376adb0","value":35}},"7673249f160d4c1c930f12f8d31c2295":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0b9e4c755ae4b14b965dc01515074da","placeholder":"​","style":"IPY_MODEL_8d2f9ec98ca146038200ee7c48109fa7","value":" 35/35 [1:11:25&lt;00:00, 160.61s/file]"}},"e1c6ccdaa6bb4f2eb55b5af7559807ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faff39882670496d904d1fb3ca512589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22310fee17d945578704f491047b4b36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e49b9c5fb9414a22a1c913c246f7b3a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"147d2073465b493898d7d8687376adb0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0b9e4c755ae4b14b965dc01515074da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d2f9ec98ca146038200ee7c48109fa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ffbbf5cc47f449789be81f9c93575fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da7cefc20fe44e27a1f1a88674602441","IPY_MODEL_05e0d387a41c4be5a0cbc1255d418025","IPY_MODEL_66a91dcffeeb4bdda341bc8adb020b17"],"layout":"IPY_MODEL_a7977685b21a4e6f8375b361a2829077"}},"da7cefc20fe44e27a1f1a88674602441":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b6e52dec6b40c49dc65f7c46beb120","placeholder":"​","style":"IPY_MODEL_5d13445ea270405d81086501c6e2abba","value":"Xử lý Train_ParaVE: 100%"}},"05e0d387a41c4be5a0cbc1255d418025":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_573c084ac03d42c59fdb884373cc6663","max":35,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff47c6e2bc2345f790c8549705cfb08b","value":35}},"66a91dcffeeb4bdda341bc8adb020b17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d35925b24514016b1ede5b707ef2e60","placeholder":"​","style":"IPY_MODEL_039d9772568a4fdebcca57d9b6895b0f","value":" 35/35 [35:43&lt;00:00, 45.41s/file]"}},"a7977685b21a4e6f8375b361a2829077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b6e52dec6b40c49dc65f7c46beb120":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d13445ea270405d81086501c6e2abba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"573c084ac03d42c59fdb884373cc6663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff47c6e2bc2345f790c8549705cfb08b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d35925b24514016b1ede5b707ef2e60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"039d9772568a4fdebcca57d9b6895b0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60ad837d30ad4787a46e64db7ab58466":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d706b999afad40c6956119a6c76ea7f4","IPY_MODEL_e9dff9f048134877acc28525122be7d3","IPY_MODEL_65ec7b0e87fa4a7daeaa2219367c7933"],"layout":"IPY_MODEL_38c36555bd394877a692b9c35f65f99c"}},"d706b999afad40c6956119a6c76ea7f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0334fb75048411fba6af185c9728fe3","placeholder":"​","style":"IPY_MODEL_7e3077c1224847ea80975ed59fc22dd6","value":"Xử lý Test_GramVar: 100%"}},"e9dff9f048134877acc28525122be7d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_560d584fd5b34cf8a4f4e9f5e8624307","max":35,"min":0,"orientation":"horizontal","style":"IPY_MODEL_727bf824461346fc9bc3077cd53ce216","value":35}},"65ec7b0e87fa4a7daeaa2219367c7933":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ea05cb9f1b84876a624655ff81ef2ee","placeholder":"​","style":"IPY_MODEL_372f4c89d05e46cab6ef69cc1322e99d","value":" 35/35 [13:08&lt;00:00, 21.23s/file]"}},"38c36555bd394877a692b9c35f65f99c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0334fb75048411fba6af185c9728fe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e3077c1224847ea80975ed59fc22dd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"560d584fd5b34cf8a4f4e9f5e8624307":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"727bf824461346fc9bc3077cd53ce216":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ea05cb9f1b84876a624655ff81ef2ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"372f4c89d05e46cab6ef69cc1322e99d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07e21aa9179a4789bb8e3605ff3cad52":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db89dcb8a1d44298a8744884a9db41e3","IPY_MODEL_4859eeda9fae482db9e259e096b672cb","IPY_MODEL_1b7c18fe0f004d1aa59cb95c5cddeca6"],"layout":"IPY_MODEL_1f127268f06143aeafbc45d7076c5d85"}},"db89dcb8a1d44298a8744884a9db41e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7602d9815b4e4c5682fef3fd8388b016","placeholder":"​","style":"IPY_MODEL_d64b43bb56a046deb1cf7997fdaa0f5c","value":"Xử lý Test_ParaVE: 100%"}},"4859eeda9fae482db9e259e096b672cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26df3c0d5c22454daebec6e003f734b5","max":35,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85dc1f27af0540b8a08483c5d920ab79","value":35}},"1b7c18fe0f004d1aa59cb95c5cddeca6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f0847eeb5314aeb98b57a5e37a71116","placeholder":"​","style":"IPY_MODEL_c90cdfe471b740178d1c93657f0cf9c5","value":" 35/35 [05:16&lt;00:00,  6.38s/file]"}},"1f127268f06143aeafbc45d7076c5d85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7602d9815b4e4c5682fef3fd8388b016":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d64b43bb56a046deb1cf7997fdaa0f5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26df3c0d5c22454daebec6e003f734b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85dc1f27af0540b8a08483c5d920ab79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f0847eeb5314aeb98b57a5e37a71116":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c90cdfe471b740178d1c93657f0cf9c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **Tạo Span Adaptation Vector cho các argument (ARG) với chiến lược Inner Content Pooling**"],"metadata":{"id":"fWlp3-F6hyHJ"}},{"cell_type":"markdown","source":["## Mục đích\n","\n","- Từ mỗi câu và các argument (ARG-0, ARG-1, ...) trong dữ liệu:\n","  - Kết hợp với adaptation vectors đã được trích xuất trước đó cho từng token.\n","  - Dùng mô hình SRL fine-tuned để lấy nhãn dự đoán per-token và trọng số classifier.\n","- Với mỗi argument, trên từng layer:\n","  - Lấy vector đầu (begin) và cuối (end) của span.\n","  - Tính vector nội dung (content vector) chỉ từ **các token bên trong** span (inner tokens, không gồm token đầu và cuối).\n","  - Ghép lại thành một Span Adaptation Vector: `[begin, end, content]`.\n","  - Lưu thêm trọng số của các inner tokens để có thể phân tích/khai thác sau."],"metadata":{"id":"TIRA4bBQh4wj"}},{"cell_type":"markdown","source":["## Đầu vào\n","\n","1. Mô hình và tokenizer\n","   - Mô hình SRL đã fine-tuned (BioBERT):\n","     - Được load từ:\n","       - `Finetuned_Models/biobert-srl-best-model`\n","     - Dùng `AutoModelForTokenClassification`.\n","   - Tokenizer tương ứng:\n","     - Dùng `AutoTokenizer.from_pretrained(final_model_path)`.\n","\n","2. Dữ liệu câu và argument (file JSON)\n","   - Nằm trong các thư mục:\n","     - `Clean_Dataset/Corpus/Split_GramVar/Train`\n","     - `Clean_Dataset/Corpus/Split_GramVar/Test`\n","     - `Clean_Dataset/Corpus/Split_ParaVE/Train`\n","     - `Clean_Dataset/Corpus/Split_ParaVE/Test`\n","   - Mỗi file JSON:\n","     - Chứa một list các phần tử, mỗi phần tử có:\n","       - `text`: câu gốc (string).\n","       - `arguments`: dict, ví dụ:\n","         - `{\"ARG-0\": \"...\", \"ARG-1\": \"...\", ...}`.\n","\n","3. Adaptation vectors cho từng câu\n","   - Nằm trong các thư mục:\n","     - `adaptation_vectors_train_gramvar_pt_aligned`\n","     - `adaptation_vectors_test_gramvar_pt_aligned`\n","     - `adaptation_vectors_train_parave_pt_aligned`\n","     - `adaptation_vectors_test_parave_pt_aligned`\n","   - Mỗi câu tương ứng một file:\n","     - `sentence_i.pt` bên trong thư mục động từ:\n","       - `.../<av_input_dir>/<verb_name>/sentence_<i>.pt`\n","   - Mỗi file `.pt` là một dict:\n","     - `{ \"layer_0\": tensor[num_tokens, hidden_dim], \"layer_1\": tensor[num_tokens, hidden_dim], ... }`.\n","\n","4. Thiết bị tính toán\n","   - Tự động chọn:\n","     - GPU (CUDA) nếu có.\n","     - CPU nếu không có GPU."],"metadata":{"id":"f8yfw5GziW-R"}},{"cell_type":"markdown","source":["## Đầu ra\n","\n","1. Span Adaptation Vectors cho từng argument\n","   - Được lưu trong các thư mục:\n","     - `span_adaptation_vectors_train_gramvar_inner_content`\n","     - `span_adaptation_vectors_test_gramvar_inner_content`\n","     - `span_adaptation_vectors_train_parave_inner_content`\n","     - `span_adaptation_vectors_test_parave_inner_content`\n","   - Bên trong mỗi thư mục trên:\n","     - Có các thư mục con theo động từ: `<verb_name>/`.\n","\n","2. Cấu trúc từng file `.pt` đầu ra\n","   - Tên file:\n","     - `sentence_<i>_<ARG_x>.pt`, ví dụ:\n","       - `sentence_0_ARG_0.pt`\n","       - `sentence_5_ARG_1.pt`\n","   - Nội dung file:\n","     - Dict với cấu trúc:\n","       - `layer_k`: span_vec (tensor) có dạng `[hidden_dim * 3]` (ghép `begin`, `end`, `content_vec`).\n","       - `layer_k_token_weights`: tensor chứa các trọng số `a_k` (hoặc rỗng) tương ứng với inner tokens trên layer đó."],"metadata":{"id":"2xzl0KaYidPp"}},{"cell_type":"markdown","source":["## Quy trình\n","\n","### 1. Thiết lập môi trường và tải mô hình\n","\n","- Import các thư viện: `torch`, `os`, `glob`, `json`, `tqdm`, `transformers`, `numpy`.\n","- Chọn thiết bị:\n","  - `device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")`.\n","- Khai báo đường dẫn gốc:\n","  - `drive_base_path = '/content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep'`.\n","- Load mô hình và tokenizer:\n","  - `final_model_path = os.path.join(drive_base_path, 'Finetuned_Models/biobert-srl-best-model')`.\n","  - `tokenizer = AutoTokenizer.from_pretrained(final_model_path)`.\n","  - `model_ft = AutoModelForTokenClassification.from_pretrained(final_model_path).to(device)`.\n","  - `model_ft.eval()`.\n","\n","### 2. Khai báo danh sách các bộ dữ liệu cần xử lý\n","\n","- `datasets_to_process` là một list các tuple:\n","  - `(name, data_dir, av_input_dir, output_dir)`.\n","- Ví dụ một phần:\n","  - `(\"Train_GramVar\", <data_dir_train_gramvar>, <av_input_dir_train_gramvar>, <output_dir_train_gramvar_vectors_inner>)`.\n","- Mỗi tuple tương ứng với:\n","  - Tên bộ dữ liệu (Train/Test + GramVar/ParaVE).\n","  - Thư mục dữ liệu JSON.\n","  - Thư mục chứa adaptation vectors.\n","  - Thư mục output để lưu span adaptation vectors.\n","\n","### 3. Hàm `find_sub_list(sl, l)`\n","\n","- Chức năng:\n","  - Tìm vị trí `(start_idx, end_idx)` của list con `sl` trong list `l`.\n","- Ứng dụng:\n","  - `sl` = tokenized argument (`arg_tokens`).\n","  - `l`  = tokenized full sentence (`full_tokens`).\n","  - Trả về `(-1, -1)` nếu không tìm thấy.\n","\n","### 4. Hàm `create_span_vectors(sentence_text, arguments, token_av_data, model, tokenizer)`\n","\n","- Mục đích:\n","  - Tạo Span Adaptation Vectors cho tất cả các argument trong một câu, với Inner Content Pooling.\n","\n","- Các bước chi tiết:\n","\n","1. Tokenize câu và chạy mô hình:\n","   - `full_tokens = tokenizer.tokenize(sentence_text)`.\n","   - Với `torch.no_grad()`:\n","     - Tạo `inputs = tokenizer(sentence_text, return_tensors=\"pt\").to(device)`.\n","     - Chạy mô hình: `logits = model(**inputs).logits`.\n","     - Lấy `predictions = argmax(logits, dim=2)` (nhãn dự đoán cho từng token).\n","   - Lấy `classifier_weights = model.classifier.weight.detach().cpu()`.\n","\n","2. Duyệt từng argument trong `arguments`:\n","   - Chỉ xét các key bắt đầu bằng `\"ARG\"` và có `arg_text` không rỗng.\n","   - Tokenize `arg_text` → `arg_tokens`.\n","   - Gọi `find_sub_list(arg_tokens, full_tokens)` để tìm `(start_idx, end_idx)`.\n","   - Cộng thêm 1 cho cả hai index:\n","     - Do input mô hình có `[CLS]` ở đầu.\n","   - Nếu `start_idx == 0` (trường hợp không hợp lệ) thì bỏ qua.\n","\n","3. Xử lý trên từng layer trong `token_av_data`:\n","   - `layer_av_tensor = layer_av_tensor.cpu()` để đưa về CPU.\n","   - Lấy vector begin và end:\n","     - `adap_vec_begin = layer_av_tensor[start_idx]`.\n","     - `adap_vec_end = layer_av_tensor[end_idx]`.\n","\n","4. Xác định inner tokens (token nội dung):\n","   - `content_start_idx = start_idx + 1`.\n","   - `content_end_idx = end_idx`.\n","   - Nếu `content_start_idx < content_end_idx`:\n","     - Có inner tokens (span dài > 2 token):\n","       - `inner_span_token_avs = layer_av_tensor[content_start_idx : content_end_idx]`.\n","       - `inner_span_token_preds = predictions[content_start_idx : content_end_idx]`.\n","   - Ngược lại:\n","     - Không có inner tokens (span dài 1 hoặc 2 token):\n","       - `inner_span_token_avs` là tensor rỗng.\n","       - `inner_span_token_preds` là array rỗng.\n","\n","5. Tính các hệ số `a_k` cho inner tokens:\n","   - Khởi tạo `a_k_list = []`.\n","   - Với mỗi inner token:\n","     - `adap_vec_tk = inner_span_token_avs[i]`.\n","     - `pred_label_id = inner_span_token_preds[i]`.\n","     - `w_r_star = classifier_weights[pred_label_id]`.\n","     - Tính:\n","       - `dot_product = torch.dot(adap_vec_tk, w_r_star)`.\n","       - `norm_w = torch.linalg.norm(w_r_star)`.\n","       - `a_k = max(0, dot_product / (norm_w + 1e-8))`.\n","     - Thêm `a_k` vào `a_k_list`.\n","   - Nếu có `a_k_list`:\n","     - `stacked_a_k = torch.stack(a_k_list)`.\n","   - Ngược lại:\n","     - `stacked_a_k = torch.empty(0)` (tensor rỗng).\n","   - `sum_a_k = torch.sum(stacked_a_k) + 1e-8`.\n","\n","6. Tính content vector từ inner tokens:\n","   - Khởi tạo:\n","     - `content_vec = torch.zeros(layer_av_tensor.shape[1], dtype=torch.float32)`.\n","   - Nếu `sum_a_k > 1e-8` và có ít nhất một inner token:\n","     - Với mỗi inner token:\n","       - `w_k = a_k_list[i] / sum_a_k`.\n","       - Cộng dồn:\n","         - `content_vec += w_k * inner_span_token_avs[i]`.\n","   - Nếu không có inner tokens hoặc `sum_a_k` gần 0:\n","     - `content_vec` giữ nguyên là vector 0 (không đóng góp nội dung).\n","\n","7. Ghép span vector và lưu kết quả:\n","   - `span_vec = torch.cat([adap_vec_begin, adap_vec_end, content_vec])`.\n","   - Lưu:\n","     - `span_vectors_per_layer[layer_name] = span_vec`.\n","     - `span_vectors_per_layer[f\"{layer_name}_token_weights\"] = stacked_a_k` (trọng số inner tokens).\n","\n","8. Lưu per-argument:\n","   - `span_vectors_all_args[arg_label] = span_vectors_per_layer`.\n","\n","- Hàm trả về:\n","  - `span_vectors_all_args`:\n","    - Dict: `{ \"ARG-0\": {layer_0: span_vec, layer_0_token_weights: ..., ...}, \"ARG-1\": {...}, ... }`.\n","\n","### 5. Vòng lặp chính trong `if __name__ == \"__main__\":`\n","\n","- Dùng để chạy toàn bộ quy trình cho tất cả các bộ dữ liệu.\n","\n","1. In thông báo bắt đầu.\n","2. Với mỗi `(name, data_dir, av_input_dir, output_dir)` trong `datasets_to_process`:\n","   - Tạo `output_dir` nếu chưa tồn tại.\n","   - Lấy danh sách các file JSON trong `data_dir`.\n","   - Nếu không tìm thấy file nào:\n","     - In cảnh báo và bỏ qua bộ dữ liệu đó.\n","   - Tạo `tqdm` để hiển thị tiến độ theo file.\n","\n","3. Với mỗi file JSON:\n","   - Suy ra `verb_name` từ tên file (bỏ `_train_set.json` hoặc `_test_set.json`).\n","   - Đọc dữ liệu:\n","     - `original_data = json.load(f)`.\n","   - Tạo thư mục:\n","     - `output_verb_dir = os.path.join(output_dir, verb_name)`.\n","\n","4. Với mỗi câu trong `original_data` (theo index `i`):\n","   - Lấy:\n","     - `sentence_text = item.get('text')`.\n","     - `arguments = item.get('arguments')`.\n","   - Nếu thiếu `sentence_text` hoặc `arguments`: bỏ qua.\n","   - Tạo đường dẫn tới adaptation vectors:\n","     - `av_path = os.path.join(av_input_dir, verb_name, f\"sentence_{i}.pt\")`.\n","   - Load:\n","     - `token_av_data = torch.load(av_path)`.\n","\n","   - Gọi:\n","     - `span_av_data_per_arg = create_span_vectors(sentence_text, arguments, token_av_data, model_ft, tokenizer)`.\n","\n","   - Nếu có kết quả:\n","     - Với mỗi `arg_label, vectors_for_this_arg`:\n","       - Tạo `safe_arg_label = arg_label.replace('-', '_')`.\n","       - Tạo `output_filename = f\"sentence_{i}_{safe_arg_label}.pt\"`.\n","       - Tạo `output_path = os.path.join(output_verb_dir, output_filename)`.\n","       - Lưu file bằng `torch.save(vectors_for_this_arg, output_path)`.\n","\n","5. Xử lý lỗi:\n","   - `FileNotFoundError`:\n","     - Bỏ qua câu đó (không in lỗi).\n","   - Các lỗi khác:\n","     - In thông báo qua `pbar.write(...)` với chỉ số câu và tên động từ.\n","   - Cập nhật progress bar sau mỗi file JSON.\n","\n","6. In thông báo hoàn tất sau khi xử lý xong toàn bộ.\n"],"metadata":{"id":"RlSdMKDBiib9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634,"referenced_widgets":["77ea2ebccf764743b56e2cdcf5459fbc","7a3a7d61efb24b74893053710158e7a6","b48a26a20f0441a7adb31d9e3d9ba3c2","7673249f160d4c1c930f12f8d31c2295","e1c6ccdaa6bb4f2eb55b5af7559807ed","faff39882670496d904d1fb3ca512589","22310fee17d945578704f491047b4b36","e49b9c5fb9414a22a1c913c246f7b3a5","147d2073465b493898d7d8687376adb0","e0b9e4c755ae4b14b965dc01515074da","8d2f9ec98ca146038200ee7c48109fa7","8ffbbf5cc47f449789be81f9c93575fd","da7cefc20fe44e27a1f1a88674602441","05e0d387a41c4be5a0cbc1255d418025","66a91dcffeeb4bdda341bc8adb020b17","a7977685b21a4e6f8375b361a2829077","43b6e52dec6b40c49dc65f7c46beb120","5d13445ea270405d81086501c6e2abba","573c084ac03d42c59fdb884373cc6663","ff47c6e2bc2345f790c8549705cfb08b","4d35925b24514016b1ede5b707ef2e60","039d9772568a4fdebcca57d9b6895b0f","60ad837d30ad4787a46e64db7ab58466","d706b999afad40c6956119a6c76ea7f4","e9dff9f048134877acc28525122be7d3","65ec7b0e87fa4a7daeaa2219367c7933","38c36555bd394877a692b9c35f65f99c","a0334fb75048411fba6af185c9728fe3","7e3077c1224847ea80975ed59fc22dd6","560d584fd5b34cf8a4f4e9f5e8624307","727bf824461346fc9bc3077cd53ce216","7ea05cb9f1b84876a624655ff81ef2ee","372f4c89d05e46cab6ef69cc1322e99d","07e21aa9179a4789bb8e3605ff3cad52","db89dcb8a1d44298a8744884a9db41e3","4859eeda9fae482db9e259e096b672cb","1b7c18fe0f004d1aa59cb95c5cddeca6","1f127268f06143aeafbc45d7076c5d85","7602d9815b4e4c5682fef3fd8388b016","d64b43bb56a046deb1cf7997fdaa0f5c","26df3c0d5c22454daebec6e003f734b5","85dc1f27af0540b8a08483c5d920ab79","1f0847eeb5314aeb98b57a5e37a71116","c90cdfe471b740178d1c93657f0cf9c5"]},"id":"ZpjpGLXtGAcn","executionInfo":{"status":"ok","timestamp":1762925998065,"user_tz":-420,"elapsed":7581578,"user":{"displayName":"Trí Trần Đức","userId":"16647398495852939072"}},"outputId":"3bdffc2d-7fba-45c1-8ac4-6e0a80644aca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sử dụng thiết bị: cuda\n","Đang tải lại mô hình Fine-tuned...\n"," -> Tải mô hình thành công!\n","\n","--- Bắt đầu quá trình tạo Span Adaptation Vector (Inner Content Pooling) ---\n","\n","=================================================\n","BẮT ĐẦU XỬ LÝ BỘ DỮ LIỆU: Train_GramVar\n"," -> Output Dir: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/span_adaptation_vectors_train_gramvar_inner_content\n","=================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Xử lý Train_GramVar:   0%|          | 0/35 [00:00<?, ?file/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77ea2ebccf764743b56e2cdcf5459fbc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","=================================================\n","BẮT ĐẦU XỬ LÝ BỘ DỮ LIỆU: Train_ParaVE\n"," -> Output Dir: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/span_adaptation_vectors_train_parave_inner_content\n","=================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Xử lý Train_ParaVE:   0%|          | 0/35 [00:00<?, ?file/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ffbbf5cc47f449789be81f9c93575fd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","=================================================\n","BẮT ĐẦU XỬ LÝ BỘ DỮ LIỆU: Test_GramVar\n"," -> Output Dir: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/span_adaptation_vectors_test_gramvar_inner_content\n","=================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Xử lý Test_GramVar:   0%|          | 0/35 [00:00<?, ?file/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ad837d30ad4787a46e64db7ab58466"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","=================================================\n","BẮT ĐẦU XỬ LÝ BỘ DỮ LIỆU: Test_ParaVE\n"," -> Output Dir: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/span_adaptation_vectors_test_parave_inner_content\n","=================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Xử lý Test_ParaVE:   0%|          | 0/35 [00:00<?, ?file/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07e21aa9179a4789bb8e3605ff3cad52"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","--- QUÁ TRÌNH TẠO SPAN ADAPTATION VECTOR (Inner Content Pooling) ĐÃ HOÀN TẤT! ---\n"]}],"source":["# Import các thư viện cần thiết\n","import torch\n","import os\n","import glob\n","import json\n","from tqdm.auto import tqdm\n","from transformers import AutoTokenizer, AutoModelForTokenClassification\n","import numpy as np\n","\n","# THIẾT LẬP CÁC ĐƯỜNG DẪN VÀ TẢI MÔ HÌNH\n","\n","# Tự động chọn GPU nếu có\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Sử dụng thiết bị: {device}\")\n","\n","# Đường dẫn thư mục gốc trên Google Drive\n","drive_base_path = '/content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep'\n","\n","# Tải lại mô hình fine-tuned để lấy trọng số classifier và chạy dự đoán\n","print(\"Đang tải lại mô hình Fine-tuned...\")\n","final_model_path = os.path.join(drive_base_path, 'Finetuned_Models/biobert-srl-best-model')\n","tokenizer = AutoTokenizer.from_pretrained(final_model_path)\n","model_ft = AutoModelForTokenClassification.from_pretrained(final_model_path).to(device)\n","model_ft.eval() # Chuyển sang chế độ đánh giá\n","print(\" -> Tải mô hình thành công!\")\n","\n","# --- DANH SÁCH CÁC BỘ DỮ LIỆU CẦN XỬ LÝ ---\n","datasets_to_process = [\n","    # --- Dữ liệu Train ---\n","    (\n","        \"Train_GramVar\",\n","        os.path.join(drive_base_path, 'Clean_Dataset/Corpus/Split_GramVar/Train'),\n","        os.path.join(drive_base_path, 'Adaptation Vector/Train/adaptation_vectors_train_gramvar_pt_aligned'),\n","        os.path.join(drive_base_path, 'span_adaptation_vectors_train_gramvar_inner_content')\n","    ),\n","    (\n","        \"Train_ParaVE\",\n","        os.path.join(drive_base_path, 'Clean_Dataset/Corpus/Split_ParaVE/Train'),\n","        os.path.join(drive_base_path, 'Adaptation Vector/Train/adaptation_vectors_train_parave_pt_aligned'),\n","        os.path.join(drive_base_path, 'span_adaptation_vectors_train_parave_inner_content')\n","    ),\n","    # --- Dữ liệu Test ---\n","    (\n","        \"Test_GramVar\",\n","        os.path.join(drive_base_path, 'Clean_Dataset/Corpus/Split_GramVar/Test'),\n","        os.path.join(drive_base_path, 'Adaptation Vector/Test/adaptation_vectors_test_gramvar_pt_aligned'),\n","        os.path.join(drive_base_path, 'span_adaptation_vectors_test_gramvar_inner_content')\n","    ),\n","    (\n","        \"Test_ParaVE\",\n","        os.path.join(drive_base_path, 'Clean_Dataset/Corpus/Split_ParaVE/Test'),\n","        os.path.join(drive_base_path, 'Adaptation Vector/Train/adaptation_vectors_test_parave_pt_aligned'),\n","        os.path.join(drive_base_path, 'span_adaptation_vectors_test_parave_inner_content')\n","    ),\n","]\n","\n","# CÁC HÀM XỬ LÝ CỐT LÕI\n","\n","def find_sub_list(sl, l):\n","    sll = len(sl)\n","    for ind in (i for i, e in enumerate(l) if e == sl[0]):\n","        if l[ind:ind+sll] == sl:\n","            return ind, ind + sll - 1\n","    return -1, -1\n","\n","def create_span_vectors(sentence_text, arguments, token_av_data, model, tokenizer):\n","    \"\"\"\n","    Tạo span adaptation vector cho tất cả các argument trong một câu.\n","    *** ĐÃ CẬP NHẬT: Content pooling chỉ tính các token BÊN TRONG (inner tokens) ***\n","    \"\"\"\n","    full_tokens = tokenizer.tokenize(sentence_text)\n","\n","    with torch.no_grad():\n","        inputs = tokenizer(sentence_text, return_tensors=\"pt\").to(device)\n","        logits = model(**inputs).logits\n","        predictions = torch.argmax(logits, dim=2)[0].cpu().numpy()\n","\n","    classifier_weights = model.classifier.weight.detach().cpu()\n","\n","    span_vectors_all_args = {}\n","\n","    for arg_label, arg_text in arguments.items():\n","        if not arg_label.startswith('ARG') or not arg_text:\n","            continue\n","\n","        arg_tokens = tokenizer.tokenize(arg_text)\n","        start_idx, end_idx = find_sub_list(arg_tokens, full_tokens)\n","\n","        start_idx += 1\n","        end_idx += 1\n","\n","        if start_idx == 0:\n","            continue\n","\n","        span_vectors_per_layer = {}\n","        for layer_name, layer_av_tensor in token_av_data.items():\n","            layer_av_tensor = layer_av_tensor.cpu()\n","\n","            # Lấy vector đầu và cuối\n","            adap_vec_begin = layer_av_tensor[start_idx]\n","            adap_vec_end = layer_av_tensor[end_idx]\n","\n","            # Xác định các token NỘI DUNG (ở giữa)\n","            content_start_idx = start_idx + 1\n","            content_end_idx = end_idx # Slicing (vd: [a:b]) sẽ không bao gồm b\n","\n","            # Lấy vector và dự đoán của các token NỘI DUNG\n","            if content_start_idx < content_end_idx:\n","                # Có token ở giữa (cho span dài > 2)\n","                inner_span_token_avs = layer_av_tensor[content_start_idx : content_end_idx]\n","                inner_span_token_preds = predictions[content_start_idx : content_end_idx]\n","            else:\n","                # Không có token ở giữa (cho span dài 1 hoặc 2)\n","                inner_span_token_avs = torch.empty(0, layer_av_tensor.shape[1], dtype=layer_av_tensor.dtype) # Tensor rỗng\n","                inner_span_token_preds = np.array([]) # Array rỗng\n","\n","            # Tính trọng số a_k CHỈ cho các token NỘI DUNG\n","            a_k_list = []\n","            for i in range(len(inner_span_token_avs)): # Vòng lặp này sẽ bỏ qua nếu span rỗng\n","                adap_vec_tk = inner_span_token_avs[i]\n","                pred_label_id = inner_span_token_preds[i]\n","                w_r_star = classifier_weights[pred_label_id]\n","\n","                dot_product = torch.dot(adap_vec_tk, w_r_star)\n","                norm_w = torch.linalg.norm(w_r_star)\n","                a_k = torch.max(torch.tensor(0.0), dot_product / (norm_w + 1e-8))\n","                a_k_list.append(a_k)\n","\n","            stacked_a_k = torch.stack(a_k_list) if a_k_list else torch.empty(0)\n","            sum_a_k = torch.sum(stacked_a_k) + 1e-8\n","\n","            # Tính content_vec CHỈ từ các token NỘI DUNG\n","            content_vec = torch.zeros(layer_av_tensor.shape[1], dtype=torch.float32)\n","            if sum_a_k > 1e-8 and len(inner_span_token_avs) > 0:\n","                for i in range(len(inner_span_token_avs)):\n","                    w_k = a_k_list[i] / sum_a_k\n","                    content_vec += w_k * inner_span_token_avs[i]\n","\n","            # Ghép vector\n","            span_vec = torch.cat([adap_vec_begin, adap_vec_end, content_vec])\n","            span_vectors_per_layer[layer_name] = span_vec\n","\n","            # Lưu trọng số (trọng số của token NỘI DUNG)\n","            span_vectors_per_layer[f\"{layer_name}_token_weights\"] = stacked_a_k\n","\n","        span_vectors_all_args[arg_label] = span_vectors_per_layer\n","\n","    return span_vectors_all_args\n","\n","# THỰC THI CHƯƠNG TRÌNH\n","\n","if __name__ == \"__main__\":\n","    print(\"\\n--- Bắt đầu quá trình tạo Span Adaptation Vector (Inner Content Pooling) ---\")\n","\n","    for name, data_dir, av_input_dir, output_dir in datasets_to_process:\n","        print(f\"\\n=================================================\")\n","        print(f\"BẮT ĐẦU XỬ LÝ BỘ DỮ LIỆU: {name}\")\n","        print(f\" -> Output Dir: {output_dir}\")\n","        print(f\"=================================================\")\n","\n","        os.makedirs(output_dir, exist_ok=True)\n","        json_files = glob.glob(os.path.join(data_dir, '*.json'))\n","\n","        if not json_files:\n","            print(f\"CẢNH BÁO: Không tìm thấy file dữ liệu gốc nào trong '{data_dir}'. Bỏ qua.\")\n","            continue\n","\n","        pbar = tqdm(total=len(json_files), desc=f\"Xử lý {name}\", unit=\"file\")\n","\n","        for json_file in json_files:\n","            verb_name = os.path.basename(json_file).replace('_test_set.json', '').replace('_train_set.json', '')\n","\n","            with open(json_file, 'r', encoding='utf-8') as f:\n","                original_data = json.load(f)\n","\n","            output_verb_dir = os.path.join(output_dir, verb_name)\n","            os.makedirs(output_verb_dir, exist_ok=True)\n","\n","            for i, item in enumerate(original_data):\n","                sentence_text = item.get('text')\n","                arguments = item.get('arguments')\n","\n","                if not sentence_text or not arguments:\n","                    continue\n","\n","                try:\n","                    av_path = os.path.join(av_input_dir, verb_name, f\"sentence_{i}.pt\")\n","                    token_av_data = torch.load(av_path)\n","\n","                    span_av_data_per_arg = create_span_vectors(sentence_text, arguments, token_av_data, model_ft, tokenizer)\n","\n","                    if span_av_data_per_arg:\n","                        for arg_label, vectors_for_this_arg in span_av_data_per_arg.items():\n","                            safe_arg_label = arg_label.replace('-', '_')\n","                            output_filename = f\"sentence_{i}_{safe_arg_label}.pt\"\n","                            output_path = os.path.join(output_verb_dir, output_filename)\n","\n","                            torch.save(vectors_for_this_arg, output_path)\n","\n","                except FileNotFoundError:\n","                    pass\n","                except Exception as e:\n","                    pbar.write(f\"Lỗi khi xử lý câu {i}, động từ {verb_name}: {e}\")\n","\n","            pbar.update(1)\n","        pbar.close()\n","\n","    print(\"\\n--- QUÁ TRÌNH TẠO SPAN ADAPTATION VECTOR (Inner Content Pooling) ĐÃ HOÀN TẤT! ---\")"]}]}