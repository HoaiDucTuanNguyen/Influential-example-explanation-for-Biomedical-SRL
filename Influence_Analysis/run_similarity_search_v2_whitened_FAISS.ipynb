{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1UFxHr-2kjvogHdlpF4Fw9aqaMX_SKim6","authorship_tag":"ABX9TyPjbqyOH/J5rKbuqKvP6SDJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a6f82fdd1506465095bb45e6f7e23072":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbee89454835479aaee3ec732e26e5fd","IPY_MODEL_1cf840e0f1a54dac9762ac01d764d0e0","IPY_MODEL_063ad5a43f3643beb70959fdbc12cae5"],"layout":"IPY_MODEL_83713777869f46e4a6e6f786379659f7"}},"fbee89454835479aaee3ec732e26e5fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c59ef536cf343cd91d4b9cc1f9aa46b","placeholder":"​","style":"IPY_MODEL_155da6587a3641b6a01b29396118b035","value":"Xây dựng Index từng Layer: 100%"}},"1cf840e0f1a54dac9762ac01d764d0e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b489615a17be458f90496d083af259d2","max":12,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db4de622877045328d84c5868d4a33b8","value":12}},"063ad5a43f3643beb70959fdbc12cae5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3891ea368b85450a941c8330e3c5f36f","placeholder":"​","style":"IPY_MODEL_a37d6d9f4b3f495fa3783b2a0ecb94a6","value":" 12/12 [00:01&lt;00:00, 11.57it/s]"}},"83713777869f46e4a6e6f786379659f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c59ef536cf343cd91d4b9cc1f9aa46b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"155da6587a3641b6a01b29396118b035":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b489615a17be458f90496d083af259d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db4de622877045328d84c5868d4a33b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3891ea368b85450a941c8330e3c5f36f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a37d6d9f4b3f495fa3783b2a0ecb94a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"369fa29368f34dacbeb58ba4e283ac46":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e511e5f9db084eb69ae25c355deddcc1","IPY_MODEL_7babe42227e141acb2aea3968e4ec365","IPY_MODEL_02a0b08c98424e2bacb1691fcc014f51"],"layout":"IPY_MODEL_ac55fe9f6ead479fbf80729bfe29c11e"}},"e511e5f9db084eb69ae25c355deddcc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d206d0a1d5841fda1827f6c90863471","placeholder":"​","style":"IPY_MODEL_bd0eac332cf246f48bed7fe86635f5f2","value":"Tìm kiếm truy vấn (Faiss L2): 100%"}},"7babe42227e141acb2aea3968e4ec365":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc4343ab37a84cb498730f8a202b94f8","max":2410,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f82a713d21c46329545a700fc78df91","value":2410}},"02a0b08c98424e2bacb1691fcc014f51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ac044a6ad4f4314a9ea587d1e4df6fc","placeholder":"​","style":"IPY_MODEL_2ebd158ae66845e6b1b9e6bc6008a09c","value":" 2410/2410 [05:28&lt;00:00,  7.78it/s]"}},"ac55fe9f6ead479fbf80729bfe29c11e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d206d0a1d5841fda1827f6c90863471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd0eac332cf246f48bed7fe86635f5f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc4343ab37a84cb498730f8a202b94f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f82a713d21c46329545a700fc78df91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ac044a6ad4f4314a9ea587d1e4df6fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ebd158ae66845e6b1b9e6bc6008a09c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Bước 2c: Tìm kiếm Top-K bằng Faiss (Whitened L2) trên Database Train đã “làm trắng”"],"metadata":{"id":"ZwbmsNpEIkuW"}},{"cell_type":"markdown","source":["## Mục tiêu của script\n","Script này thực hiện pipeline tìm kiếm (retrieval) như sau:\n","- **Database nền (Train)**: đã được **làm trắng (whitened)** từ Bước 2b.\n","- **Database truy vấn (Test)**: vẫn là **vector gốc** (chưa whiten).\n","- **Ma trận whitening (mean + W)**: lấy từ Bước 2a.\n","\n","Với mỗi truy vấn trong Test:\n","1. **Whiten vector truy vấn** (theo từng layer) bằng `mean` và `W` tương ứng.\n","2. Dùng **Faiss IndexFlatL2** để tính **khoảng cách L2** giữa truy vấn (đã whiten) và DB train (đã whiten) theo từng layer.\n","3. **Cộng dồn khoảng cách L2 qua 12 layer** để ra “tổng khoảng cách” cuối cùng.\n","4. Lấy **Top-K** mẫu có **tổng khoảng cách nhỏ nhất**.\n","5. Lưu kết quả ra file JSON gồm `query_info` và danh sách `neighbors`."],"metadata":{"id":"LXxn17tcIonV"}},{"cell_type":"markdown","source":["## Điều kiện chạy trong Colab\n","- Đã cài:\n","  - `!pip install faiss-gpu` (hoặc `faiss-cpu`)\n","- Đã **Restart Runtime** sau khi cài Faiss."],"metadata":{"id":"kHFCzhHGIpQ5"}},{"cell_type":"markdown","source":["## Thư viện sử dụng\n","- `faiss`: xây dựng index và tìm kiếm L2 nhanh.\n","- `torch`: load vector `.pt`, whitening query (matmul), no_grad.\n","- `os`: đường dẫn file và tạo thư mục output.\n","- `json`: load metadata và lưu kết quả search.\n","- `numpy`: thao tác mảng khoảng cách và sort Top-K.\n","- `tqdm.auto`: progress bar cho build index và tìm kiếm.\n","- `sys`: import sẵn (trong code hiện tại **chưa dùng**)."],"metadata":{"id":"uomLX95kIrE3"}},{"cell_type":"markdown","source":["## 1) Cấu hình chính\n","- `K = 5`  \n","  Số lượng hàng xóm gần nhất cần lấy (Top-K).\n","\n","- `D = 2304`  \n","  Kích thước của mỗi vector (dimension).\n","\n","- `NUM_LAYERS = 12`  \n","  Số layer vector (layer_1 → layer_12).\n","\n","### Chạy trên CPU để tránh lỗi\n","Script cố tình **khóa CPU**:\n","- `device = torch.device(\"cpu\")`\n","- `use_gpu = False`\n","\n","Ý nghĩa:\n","- Whitening query vẫn dùng PyTorch nhưng chạy CPU.\n","- Faiss cũng chạy CPU (không dùng GPU)."],"metadata":{"id":"c66c_35HIsc8"}},{"cell_type":"markdown","source":["## 2) Thiết lập đường dẫn I/O\n","\n","### Thư mục\n","- `db_cache_dir`: nơi chứa các file database vector và metadata.\n","- `output_results_dir`: nơi lưu file kết quả search (`search_results/`).\n","\n","### Input files\n","1) **Train DB (đã whiten)** — từ Bước 2b  \n","- `combined_train_db_vectors_v2_WHITENED.pt`  \n","- `combined_train_db_metadata_v2_inner_content.json`\n","\n","2) **Test DB (gốc)** — từ Bước 1  \n","- `combined_TEST_db_vectors_v2_inner_content.pt`  \n","- `combined_TEST_db_metadata_v2_inner_content.json`\n","\n","3) **Whitening matrices** — từ Bước 2a  \n","- `mahalanobis_data_v2_inner_content.pt`\n","\n","### Output file\n","- `search_results_top{K}_v2_WHITENED_L2.json`  \n","Chứa danh sách kết quả cho toàn bộ query trong Test."],"metadata":{"id":"TsuAGmayIumC"}},{"cell_type":"markdown","source":["## 3) Tải Database Nền (Train đã whiten)\n","- Load tensor:\n","  - `train_vectors_db_whitened = torch.load(..., map_location='cpu')`\n","  - Shape: `[N, 12, 2304]`\n","- Load metadata:\n","  - `train_metadata_db = json.load(...)`\n","- Kiểm tra số lượng:\n","  - `N_samples = len(train_metadata_db)`\n","  - `len(train_vectors_db_whitened) == N_samples`\n","\n","Nếu load lỗi → dừng chương trình."],"metadata":{"id":"ugjVtqYoIwhj"}},{"cell_type":"markdown","source":["## 4) Tải Database Truy vấn (Test gốc)\n","- Load tensor:\n","  - `test_vectors_db_original = torch.load(..., map_location='cpu')`\n","  - Shape: `[M, 12, 2304]`\n","- Load metadata:\n","  - `test_metadata_db = json.load(...)`\n","- Kiểm tra số lượng:\n","  - `M_samples = len(test_metadata_db)`\n","  - `len(test_vectors_db_original) == M_samples`\n","\n","Nếu load lỗi → dừng chương trình."],"metadata":{"id":"4JG2R8uMIx-r"}},{"cell_type":"markdown","source":["## 5) Tải Ma trận Whitening (mean và W)\n","- Load:\n","  - `mahalanobis_data = torch.load(..., map_location=device)`\n","- Dữ liệu chứa:\n","  - `mahalanobis_data['means']['layer_k']` shape `(2304,)`\n","  - `mahalanobis_data['whitening_matrices']['layer_k']` shape `(2304, 2304)`\n","\n","Trong code hiện tại, `device` là CPU nên toàn bộ mean/W ở CPU."],"metadata":{"id":"E74E_2gYIzhx"}},{"cell_type":"markdown","source":["## 6) Xây dựng Faiss IndexFlatL2 cho 12 layer\n","Mục tiêu:\n","- Mỗi layer có một index riêng để search L2 nhanh.\n","\n","Với mỗi `layer_idx`:\n","1. Trích vector Train layer đó:\n","   - `layer_train_vectors = train_vectors_db_whitened[:, layer_idx, :]`\n","   - Shape: `[N, 2304]`\n","2. Đưa sang numpy float32:\n","   - `.numpy().astype('float32')`\n","3. Tạo index L2:\n","   - `index = faiss.IndexFlatL2(D)`\n","4. Thêm toàn bộ vector vào index:\n","   - `index.add(layer_train_vectors)`\n","5. Lưu index vào `faiss_indexes`\n","\n","Sau khi xong:\n","- `del train_vectors_db_whitened` để giải phóng RAM.\n","\n","> Ghi chú: `IndexFlatL2` là index brute-force (chính xác), có thể chậm nếu N rất lớn, nhưng đơn giản và chuẩn."],"metadata":{"id":"J2-qv4IPI1S9"}},{"cell_type":"markdown","source":["## 7) Thực hiện tìm kiếm cho từng query\n","\n","### Ý tưởng tổng quát\n","Với mỗi query (Test):\n","- Tạo mảng `total_distances_L2` kích thước `[N_samples]` để **cộng dồn khoảng cách** qua 12 layer.\n","- Lặp từng layer:\n","  1. Whiten query layer đó: `(q - mean) @ W^T`\n","  2. Faiss search trên index layer đó để lấy khoảng cách với toàn bộ DB.\n","  3. Chuyển từ khoảng cách bình phương sang L2 thật: `sqrt(d^2)`\n","  4. Cộng vào `total_distances_L2`\n","\n","Cuối cùng:\n","- Sort `total_distances_L2` và lấy Top-K nhỏ nhất."],"metadata":{"id":"HWJCOT08I3Hj"}},{"cell_type":"markdown","source":["### 7.1 Khởi tạo cho mỗi query\n","- `query_metadata = test_metadata_db[query_idx]`\n","- `query_vector_original = test_vectors_db_original[query_idx]`  \n","  Shape: `[12, 2304]`\n","\n","Tạo mảng cộng dồn:\n","- `total_distances_L2 = np.zeros(N_samples, dtype='float32')`"],"metadata":{"id":"sfh7Ff8II5M5"}},{"cell_type":"markdown","source":["### 7.2 Lặp qua 12 layer của query\n","Với mỗi `layer_idx`:\n","- `layer_name = f\"layer_{layer_idx+1}\"`\n","\n","#### (1) Whitening query theo layer\n","- Lấy:\n","  - `mean = mahalanobis_data['means'][layer_name]`\n","  - `W = mahalanobis_data['whitening_matrices'][layer_name]`\n","- Vector query layer gốc:\n","  - `query_vec_original_layer = query_vector_original[layer_idx]` shape `(2304,)`\n","- Center:\n","  - `query_centered = query_vec_original_layer - mean`\n","- Whiten:\n","  - `query_whitened = query_centered @ W.T` shape `(2304,)`\n","\n","Chuyển sang numpy để Faiss xử lý:\n","- `query_whitened_np` shape `(1, 2304)` float32"],"metadata":{"id":"lMvL3PX_I6rL"}},{"cell_type":"markdown","source":["#### (2) Search Faiss trên layer tương ứng\n","- Lấy index:\n","  - `index_for_this_layer = faiss_indexes[layer_idx]`\n","\n","Search:\n","- `index.search(query_whitened_np, N_samples)`\n","\n","Ở đây `k = N_samples` nghĩa là:\n","- lấy **kết quả cho toàn bộ DB** (tức brute-force trả ra danh sách full sorted theo khoảng cách).\n","\n","Faiss trả:\n","- `D_matrix_L2_squared`: khoảng cách L2 bình phương, shape `(1, N_samples)`\n","- `I_matrix`: chỉ số tương ứng (sorted), shape `(1, N_samples)`"],"metadata":{"id":"Ryezrn6iI9ar"}},{"cell_type":"markdown","source":["#### (3) “Giải-sắp-xếp” (unsort) để khớp đúng index gốc\n","Faiss trả kết quả theo thứ tự tăng dần khoảng cách, nên cần đưa về đúng vị trí `[0..N-1]` để cộng dồn:\n","- `distances_L2_squared_sorted = D_matrix_L2_squared[0]`\n","- `indices_sorted = I_matrix[0]`\n","\n","Tạo mảng unsorted:\n","- `unsorted_distances_L2_squared[indices_sorted] = distances_L2_squared_sorted`\n","\n","Sau đó lấy L2 thật:\n","- `distances_L2 = sqrt(unsorted_distances_L2_squared)`"],"metadata":{"id":"QfG0glseI_s4"}},{"cell_type":"markdown","source":["#### (4) Cộng dồn khoảng cách qua layer\n","- `total_distances_L2 += distances_L2`\n","\n","Kết quả sau 12 layer:\n","- `total_distances_L2[j]` = tổng L2 của query với vector train thứ `j` trên toàn bộ layer."],"metadata":{"id":"Fu1lXjyUJBXn"}},{"cell_type":"markdown","source":["### 7.3 Lấy Top-K hàng xóm\n","- `match_indices = argsort(total_distances_L2)[:K]`\n","- `match_distances = total_distances_L2[match_indices]`\n","\n","Tạo danh sách `top_k_matches` gồm:\n","- `match_db_index`: chỉ số vector trong DB train\n","- `total_L2_distance_whitened`: tổng khoảng cách L2 (cộng 12 layer)\n","- `match_metadata`: metadata tương ứng từ `train_metadata_db`"],"metadata":{"id":"0Desrm6zJDct"}},{"cell_type":"markdown","source":["### 7.4 Ghi kết quả cho từng query\n","Mỗi query sẽ được lưu dưới dạng:\n","- `query_info`: metadata của query\n","- `neighbors`: danh sách K kết quả gần nhất\n","\n","Tất cả query được gom vào:\n","- `all_search_results`"],"metadata":{"id":"qqWAfrD0JFDC"}},{"cell_type":"markdown","source":["## 8) Lưu kết quả ra file JSON\n","- Ghi:\n","  - `json.dump(all_search_results, indent=4)`\n","- File output:\n","  - `search_results_top{K}_v2_WHITENED_L2.json`\n"],"metadata":{"id":"QgvboihYJGeT"}},{"cell_type":"markdown","source":["## Kết quả đầu ra\n","File JSON kết quả có dạng:\n","- Danh sách length = `M_samples`\n","- Mỗi phần tử gồm:\n","  - `query_info`: thông tin query\n","  - `neighbors`: Top-K kết quả (index + score + metadata)"],"metadata":{"id":"Py2eTzAAJHts"}},{"cell_type":"markdown","source":["## Ghi chú hiệu năng (quan trọng)\n","- Việc gọi:\n","  - `index.search(query, N_samples)`\n","  là rất nặng vì lấy **toàn bộ** khoảng cách cho mỗi layer và mỗi query.\n","- Nếu `N_samples` lớn, bước này sẽ:\n","  - chậm\n","  - tốn RAM/CPU\n","\n","Nếu muốn tối ưu, có thể:\n","- chỉ search `k` nhỏ hơn (ví dụ 1000), rồi cộng dồn trên tập ứng viên\n","- hoặc dùng IVF/HNSW trong Faiss để approximate search\n","- hoặc gộp vector 12-layer thành một vector lớn rồi index một lần (tuỳ thiết kế)\n"],"metadata":{"id":"C3hDDPioJJHK"}},{"cell_type":"code","source":["!pip install faiss-cpu"],"metadata":{"id":"1_ddUT4juKtj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766241620395,"user_tz":-420,"elapsed":4509,"user":{"displayName":"Trí Trần Đức","userId":"16647398495852939072"}},"outputId":"9cde8b5b-fc3b-41a3-82ab-7e042200719b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-cpu\n","  Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n","Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.13.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":570,"referenced_widgets":["a6f82fdd1506465095bb45e6f7e23072","fbee89454835479aaee3ec732e26e5fd","1cf840e0f1a54dac9762ac01d764d0e0","063ad5a43f3643beb70959fdbc12cae5","83713777869f46e4a6e6f786379659f7","3c59ef536cf343cd91d4b9cc1f9aa46b","155da6587a3641b6a01b29396118b035","b489615a17be458f90496d083af259d2","db4de622877045328d84c5868d4a33b8","3891ea368b85450a941c8330e3c5f36f","a37d6d9f4b3f495fa3783b2a0ecb94a6","369fa29368f34dacbeb58ba4e283ac46","e511e5f9db084eb69ae25c355deddcc1","7babe42227e141acb2aea3968e4ec365","02a0b08c98424e2bacb1691fcc014f51","ac55fe9f6ead479fbf80729bfe29c11e","5d206d0a1d5841fda1827f6c90863471","bd0eac332cf246f48bed7fe86635f5f2","dc4343ab37a84cb498730f8a202b94f8","2f82a713d21c46329545a700fc78df91","2ac044a6ad4f4314a9ea587d1e4df6fc","2ebd158ae66845e6b1b9e6bc6008a09c"]},"id":"hgTrRCmKjXkv","executionInfo":{"status":"ok","timestamp":1766241992358,"user_tz":-420,"elapsed":371940,"user":{"displayName":"Trí Trần Đức","userId":"16647398495852939072"}},"outputId":"af6775ff-2f2f-44d9-ef0b-ffeaed7f154c"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Bắt đầu Bước 2c: Tìm kiếm (Whitened L2 - Faiss) ---\n","Phương pháp: 'Làm trắng' query và tìm L2 (Euclidean) trên DB đã 'làm trắng'.\n","Sử dụng thiết bị: cpu (Faiss GPU: False)\n","DB 'Làm trắng' (Train): /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/cached_databases/combined_train_db_vectors_v2_WHITENED.pt\n","DB Gốc (Test): /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/cached_databases/combined_TEST_db_vectors_v2_inner_content.pt\n","File ma trận: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/cached_databases/mahalanobis_data_v2_inner_content.pt\n","Kết quả sẽ lưu tại: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/search_results/search_results_top5_v2_WHITENED_L2.json\n","\n","Đang tải Database Nền (ĐÃ LÀM TRẮNG)...\n"," -> Tải thành công 15521 vector Train đã 'làm trắng'.\n","\n","Đang tải Database Truy vấn (GỐC)...\n"," -> Tải thành công 2410 vector Test (truy vấn).\n","\n","Đang tải Ma trận Whitening (mean và W)...\n"," -> Tải thành công 12 ma trận.\n","\n","Đang xây dựng Faiss Index (L2) cho 12 layer...\n"]},{"output_type":"display_data","data":{"text/plain":["Xây dựng Index từng Layer:   0%|          | 0/12 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6f82fdd1506465095bb45e6f7e23072"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" -> Xây dựng 12 Index (L2) thành công!\n","\n","Bắt đầu tìm kiếm Top-5 cho 2410 truy vấn...\n"]},{"output_type":"display_data","data":{"text/plain":["Tìm kiếm truy vấn (Faiss L2):   0%|          | 0/2410 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"369fa29368f34dacbeb58ba4e283ac46"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" -> Tìm kiếm hoàn tất!\n","\n","Đang lưu 2410 kết quả truy vấn vào file...\n"," -> Đã lưu kết quả thành công: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/search_results/search_results_top5_v2_WHITENED_L2.json\n","\n","--- BƯỚC 2c (TÌM KIẾM FAISS L2) HOÀN TẤT! ---\n"]}],"source":["# --- CELL 2: IMPORT & CODE CHÍNH ---\n","# Giả định bạn đã chạy \"!pip install faiss-gpu\" trong Cell 1\n","# và đã KHỞI ĐỘNG LẠI THỜI GIAN CHẠY (Runtime -> Restart Runtime)\n","\n","import faiss\n","import torch\n","import os\n","import json\n","import numpy as np\n","from tqdm.auto import tqdm\n","import sys\n","\n","print(\"--- Bắt đầu Bước 2c: Tìm kiếm (Whitened L2 - Faiss) ---\")\n","print(\"Phương pháp: 'Làm trắng' query và tìm L2 (Euclidean) trên DB đã 'làm trắng'.\")\n","\n","# --- 1. CẤU HÌNH ---\n","K = 5 # Số lượng vector tương đồng gần nhất cần tìm (Top-K)\n","D = 2304 # Kích thước của mỗi vector\n","NUM_LAYERS = 12\n","\n","# SỬA LỖI: Buộc script chạy trên CPU\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# use_gpu = torch.cuda.is_available()\n","device = torch.device(\"cpu\")\n","use_gpu = False\n","print(f\"Sử dụng thiết bị: {device} (Faiss GPU: {use_gpu})\")\n","\n","\n","# --- 2. THIẾT LẬP CÁC ĐƯỜNG DẪN ---\n","drive_base_path = '/content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep'\n","db_cache_dir = os.path.join(drive_base_path, 'cached_databases')\n","output_results_dir = os.path.join(drive_base_path, 'search_results')\n","os.makedirs(output_results_dir, exist_ok=True)\n","\n","# --- Các file INPUT ---\n","\n","# 1. Database NỀN (ĐÃ LÀM TRẮNG) - (Từ Bước 2b)\n","train_vectors_file = os.path.join(db_cache_dir, 'combined_train_db_vectors_v2_WHITENED.pt')\n","train_metadata_file = os.path.join(db_cache_dir, 'combined_train_db_metadata_v2_inner_content.json') # Metadata gốc\n","\n","# 2. Database TRUY VẤN (GỐC) - (Từ Bước 1)\n","test_vectors_file = os.path.join(db_cache_dir, 'combined_TEST_db_vectors_v2_inner_content.pt')\n","test_metadata_file = os.path.join(db_cache_dir, 'combined_TEST_db_metadata_v2_inner_content.json') # Metadata gốc\n","\n","# 3. Ma trận Whitening - (Từ Bước 2a)\n","mahalanobis_data_file = os.path.join(db_cache_dir, 'mahalanobis_data_v2_inner_content.pt')\n","\n","# --- File OUTPUT (Tên file mới) ---\n","results_file = os.path.join(output_results_dir, f'search_results_top{K}_v2_WHITENED_L2.json') # Tên file kết quả mới\n","\n","print(f\"DB 'Làm trắng' (Train): {train_vectors_file}\")\n","print(f\"DB Gốc (Test): {test_vectors_file}\")\n","print(f\"File ma trận: {mahalanobis_data_file}\")\n","print(f\"Kết quả sẽ lưu tại: {results_file}\")\n","\n","# --- 3. TẢI DATABASE NỀN (ĐÃ LÀM TRẮNG) ---\n","print(\"\\nĐang tải Database Nền (ĐÃ LÀM TRẮNG)...\")\n","try:\n","    train_vectors_db_whitened = torch.load(train_vectors_file, map_location='cpu') # [N, 12, 2304]\n","    with open(train_metadata_file, 'r', encoding='utf-8') as f:\n","        train_metadata_db = json.load(f)\n","    N_samples = len(train_metadata_db)\n","    assert len(train_vectors_db_whitened) == N_samples\n","    print(f\" -> Tải thành công {N_samples} vector Train đã 'làm trắng'.\")\n","except Exception as e:\n","    print(f\"LỖI: Không thể tải database Train 'làm trắng'. {e}\")\n","    exit()\n","\n","# --- 4. TẢI DATABASE TRUY VẤN (GỐC) ---\n","print(\"\\nĐang tải Database Truy vấn (GỐC)...\")\n","try:\n","    test_vectors_db_original = torch.load(test_vectors_file, map_location='cpu') # [M, 12, 2304]\n","    with open(test_metadata_file, 'r', encoding='utf-8') as f:\n","        test_metadata_db = json.load(f)\n","    M_samples = len(test_metadata_db)\n","    assert len(test_vectors_db_original) == M_samples\n","    print(f\" -> Tải thành công {M_samples} vector Test (truy vấn).\")\n","except Exception as e:\n","    print(f\"LỖI: Không thể tải database Test. {e}\")\n","    exit()\n","\n","# --- 5. TẢI MA TRẬN WHITENING ---\n","print(\"\\nĐang tải Ma trận Whitening (mean và W)...\")\n","try:\n","    mahalanobis_data = torch.load(mahalanobis_data_file, map_location=device) # Tải thẳng lên GPU\n","    print(f\" -> Tải thành công {len(mahalanobis_data['means'])} ma trận.\")\n","except Exception as e:\n","    print(f\"LỖI: Không thể tải file ma trận. {e}\")\n","    exit()\n","\n","# --- 6. XÂY DỰNG FAISS INDEX (L2) TỪ DB ĐÃ LÀM TRẮNG ---\n","print(\"\\nĐang xây dựng Faiss Index (L2) cho 12 layer...\")\n","\n","faiss_indexes = []\n","for layer_idx in tqdm(range(NUM_LAYERS), desc=\"Xây dựng Index từng Layer\"):\n","    # 1. Trích xuất vector [N, 2304] của layer này TỪ DB ĐÃ LÀM TRẮNG\n","    layer_train_vectors = train_vectors_db_whitened[:, layer_idx, :].numpy().astype('float32')\n","\n","    # 2. Tạo index L2 (Euclidean)\n","    index = faiss.IndexFlatL2(D)\n","\n","    if use_gpu:\n","        res = faiss.StandardGpuResources()\n","        index = faiss.index_cpu_to_gpu(res, 0, index)\n","\n","    # 3. Thêm vector vào index\n","    index.add(layer_train_vectors)\n","    faiss_indexes.append(index)\n","\n","print(\" -> Xây dựng 12 Index (L2) thành công!\")\n","# Giải phóng bộ nhớ, không cần DB train trên CPU nữa\n","del train_vectors_db_whitened\n","\n","# --- 7. THỰC HIỆN TÌM KIẾM (NHANH) ---\n","print(f\"\\nBắt đầu tìm kiếm Top-{K} cho {M_samples} truy vấn...\")\n","\n","all_search_results = [] # Lưu kết quả cuối cùng\n","\n","with torch.no_grad():\n","    for query_idx in tqdm(range(M_samples), desc=\"Tìm kiếm truy vấn (Faiss L2)\"):\n","        query_metadata = test_metadata_db[query_idx]\n","        query_vector_original = test_vectors_db_original[query_idx].to(device) # [12, 2304]\n","\n","        # Mảng [N_samples] (ví dụ: [15521]) để cộng dồn tổng khoảng cách\n","        total_distances_L2 = np.zeros(N_samples, dtype='float32')\n","\n","        # Lặp qua 12 layer của vector truy vấn này\n","        for layer_idx in range(NUM_LAYERS):\n","            layer_name = f\"layer_{layer_idx+1}\"\n","\n","            # 1. \"Làm trắng\" vector query của layer này\n","            mean = mahalanobis_data['means'][layer_name] # Đã ở trên GPU\n","            W = mahalanobis_data['whitening_matrices'][layer_name] # Đã ở trên GPU\n","\n","            query_vec_original_layer = query_vector_original[layer_idx] # [2304]\n","\n","            query_centered = query_vec_original_layer - mean\n","            query_whitened = torch.matmul(query_centered, W.T) # [2304]\n","\n","            # Chuyển về numpy [1, 2304] để Faiss xử lý\n","            query_whitened_np = query_whitened.unsqueeze(0).cpu().numpy().astype('float32')\n","\n","            # 2. Lấy index L2 của layer tương ứng\n","            index_for_this_layer = faiss_indexes[layer_idx]\n","\n","            # 3. Tìm kiếm L2! (Tìm K=N_samples, tức là lấy hết)\n","            D_matrix_L2_squared, I_matrix = index_for_this_layer.search(query_whitened_np, N_samples)\n","\n","            distances_L2_squared_sorted = D_matrix_L2_squared[0]\n","            indices_sorted = I_matrix[0]\n","\n","            # \"Giải-sắp-xếp\" (unsort) mảng khoảng cách\n","            unsorted_distances_L2_squared = np.empty_like(distances_L2_squared_sorted)\n","            unsorted_distances_L2_squared[indices_sorted] = distances_L2_squared_sorted\n","\n","            # Lấy căn bậc 2 để ra khoảng cách L2 (Euclidean) thực sự\n","            distances_L2 = np.sqrt(unsorted_distances_L2_squared)\n","\n","            # 4. Cộng dồn vào tổng khoảng cách (mảng đã unsort)\n","            total_distances_L2 += distances_L2\n","\n","        # 5. TÌM TOP-K (K index có tổng khoảng cách NHỎ NHẤT)\n","        match_indices = np.argsort(total_distances_L2)[:K]\n","        match_distances = total_distances_L2[match_indices]\n","\n","        # 6. Xử lý kết quả\n","        top_k_matches = []\n","        for i in range(K):\n","            match_index = match_indices[i]\n","            match_score = match_distances[i]\n","            match_metadata = train_metadata_db[match_index]\n","\n","            top_k_matches.append({\n","                'match_db_index': int(match_index),\n","                'total_L2_distance_whitened': float(match_score), # Đây là TỔNG khoảng cách L2\n","                'match_metadata': match_metadata\n","            })\n","\n","        all_search_results.append({\n","            'query_info': query_metadata,\n","            'neighbors': top_k_matches\n","        })\n","\n","print(\" -> Tìm kiếm hoàn tất!\")\n","\n","# --- 8. LƯU KẾT QUẢ ---\n","print(f\"\\nĐang lưu {len(all_search_results)} kết quả truy vấn vào file...\")\n","try:\n","    with open(results_file, 'w', encoding='utf-8') as f:\n","        json.dump(all_search_results, f, indent=4)\n","    print(f\" -> Đã lưu kết quả thành công: {results_file}\")\n","except Exception as e:\n","    print(f\"LỖI khi lưu file kết quả: {e}\")\n","\n","print(\"\\n--- BƯỚC 2c (TÌM KIẾM FAISS L2) HOÀN TẤT! ---\")"]},{"cell_type":"code","source":[],"metadata":{"id":"8vozRQ6ZND-1"},"execution_count":null,"outputs":[]}]}