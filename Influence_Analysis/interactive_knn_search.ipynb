{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Y3SfkTWfzTPBy4FoZzkhQDFsDJzz2lNA","authorship_tag":"ABX9TyOnn7ze3tEzaDlcQ1EJYr3l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Công cụ **tìm kiếm tương tác k-NN** cho **Span Adaptation Vectors** (Test → Train) với **trọng số lớp**"],"metadata":{"id":"FWo89fNNc0z8"}},{"cell_type":"markdown","source":["- **Mục đích**\n","  - Cho phép bạn **nhập đường dẫn 1 file Span AV (.pt) của mẫu Test** và nhận về **K láng giềng gần nhất** trong **DB Train** (GramVar + ParaVE) theo **điểm tương đồng có trọng số theo lớp**.\n","  - In ra: điểm số, nguồn (dataset/verb/arg), **câu gốc** của neighbor (lấy từ JSON Train), và tên file vector gốc.\n"],"metadata":{"id":"GK_U0Yoxc4qh"}},{"cell_type":"markdown","source":["- **Đầu vào bắt buộc**\n","  - Trọng số lớp đã học (softmax 12 lớp):  \n","    `.../matching_results/learned_layer_weights.pt`\n","  - Database Train đã cache:\n","    - Vectors (tensor): `.../cached_databases/combined_train_db_vectors.pt`  \n","      > Dạng `[N_spans, 12, 2304]` (12 lớp; 2304 = concat `[begin || end || content]`).\n","    - Metadata (json): `.../cached_databases/combined_train_db_metadata.json`  \n","      ```json\n","      {\"verb_name\":\"interact\",\"arg_label\":\"ARG-0\",\n","       \"original_file\":\"sentence_123_ARG_0.pt\",\n","       \"source_dataset\":\"span_adaptation_vectors_train_parave\"}\n","      ```\n","  - Map thư mục Train gốc để **tra cứu text**:\n","    ```\n","    span_adaptation_vectors_train_gramvar -> .../Split_GramVar/Train\n","    span_adaptation_vectors_train_parave -> .../Split_ParaVE/Train\n","    ```\n"],"metadata":{"id":"0ZKkBckwc5VQ"}},{"cell_type":"markdown","source":["- **Đầu vào khi chạy**\n","  - Trong vòng lặp, nhập **đường dẫn file test** dạng:  \n","    `.../span_adaptation_vectors_test_<parave|gramvar>/<verb>/sentence_<i>_ARG_<k>.pt`"],"metadata":{"id":"nSTJ1ktTc8Se"}},{"cell_type":"markdown","source":["- **Đầu ra**\n","  - In ra console:\n","    - **Top-K neighbors** (K = 5 mặc định) gồm: `score`, `source_dataset / verb / arg`, **câu gốc** của neighbor (đọc từ `<verb>_train_set.json` dựa vào `sentence_<idx>`), và `original_file`."],"metadata":{"id":"ea4WZKpzc-EZ"}},{"cell_type":"markdown","source":["- **Cách tính điểm (trọng số lớp)**\n","  - Với test vector $T \\in \\mathbb{R}^{12\\times 2304}$ và mỗi DB vector $D_j \\in \\mathbb{R}^{12\\times 2304}$:\n","    1. Tính cosine cho **mỗi lớp** $l=1..12$:\n","\n","  $$\\text{sim}_{j,l} = \\cos(T_l, D_{j,l})$$\n","  \n","    2. Lấy trọng số lớp $w_l$ đã học (softmax, $\\sum_l w_l = 1$).\n","    3. **Điểm cuối**:\n","  $$\n","  \\text{score}_j = \\sum_{l=1}^{12} w_l \\cdot \\text{sim}_{j,l}.\n","  $$\n","  - Chọn **Top-K** theo $\\text{score}_j$."],"metadata":{"id":"GF03X9Xdc_9C"}},{"cell_type":"markdown","source":["- **Quy trình hoạt động**\n","  1. **Tải trọng số** lớp và **DB Train** (vectors + metadata), chuyển DB lên **GPU** nếu có.\n","  2. Nhập đường dẫn **file Span AV Test** → kiểm tra đủ **12 lớp**.\n","  3. **Stack 12 lớp** của test thành tensor `[12, 2304]`.\n","  4. Tính **cosine theo lớp** với toàn bộ DB → nhân trọng số → tổng thành **điểm**.\n","  5. Lấy **Top-K**; với mỗi neighbor:\n","     - Dựa vào `original_file` (regex `sentence_(\\d+)_`) → lấy **sentence_idx**.\n","     - Mở đúng JSON Train gốc:  \n","       `<train_root>/<verb>_train_set.json` → lấy **sentence_text** tại `sentence_idx`.\n","  6. In kết quả ra màn hình."],"metadata":{"id":"UaSLGykwdy8a"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOBvwQ1uVr5f","executionInfo":{"status":"ok","timestamp":1761746269966,"user_tz":-420,"elapsed":264787,"user":{"displayName":"Trí Trần Đức","userId":"16647398495852939072"}},"outputId":"9f6a6d95-1fa8-448f-a93a-cb3c31d09433"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sử dụng thiết bị: cpu\n","--- Bước 1: Tải trọng số quan trọng của các lớp ---\n"," -> Tải trọng số thành công!\n","\n","--- Bước 2: Tải cơ sở dữ liệu Train ---\n"," -> Tải thành công DB với 15521 span.\n","Chuyển DB sang 'cpu'...\n"," -> Chuyển thành công!\n","\n","--- Bắt đầu chế độ tìm kiếm tương tác ---\n","Nhập đường dẫn đến file Span AV (.pt) của mẫu test bạn muốn tìm.\n","Nhấn Enter hoặc gõ 'quit' để thoát.\n","\n","Nhập đường dẫn file test Span AV: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/span_adaptation_vectors_train_gramvar/abolish/sentence_1_ARG_0.pt\n","\n","--- Kết quả tìm kiếm cho: sentence_1_ARG_0.pt ---\n","Động từ: abolish, Argument: ARG-0\n","\n","5 láng giềng gần nhất trong tập Train:\n","\n","1. Score: 1.0000\n","   Nguồn: span_adaptation_vectors_train_gramvar / abolish / ARG-0\n","   Câu gốc: One mutation abolishes RNA expression from the altered allele.\n","   File vector gốc: sentence_1_ARG_0.pt\n","\n","2. Score: 0.9747\n","   Nguồn: span_adaptation_vectors_train_gramvar / abolish / ARG-0\n","   Câu gốc: One mutation can abolish RNA expression from the altered allele.\n","   File vector gốc: sentence_2_ARG_0.pt\n","\n","3. Score: 0.9697\n","   Nguồn: span_adaptation_vectors_train_gramvar / abolish / ARG-0\n","   Câu gốc: One mutation will abolish RNA expression from the altered allele.\t\n","   File vector gốc: sentence_3_ARG_0.pt\n","\n","4. Score: 0.9659\n","   Nguồn: span_adaptation_vectors_train_gramvar / abolish / ARG-0\n","   Câu gốc: One mutation abolished RNA expression from the altered allele.\n","   File vector gốc: sentence_0_ARG_0.pt\n","\n","5. Score: 0.8935\n","   Nguồn: span_adaptation_vectors_train_parave / abolish / ARG-0\n","   Câu gốc: a mutation abolishes expression of RNA (Jimnez et al., 1999).\n","   File vector gốc: sentence_4_ARG_0.pt\n","\n","Nhập đường dẫn file test Span AV: This construct, as our study suggested, has been transformed into the yeast strain HF7c (Clontech)\n","LỖI: File không tồn tại: This construct, as our study suggested, has been transformed into the yeast strain HF7c (Clontech)\n","\n","Nhập đường dẫn file test Span AV: This construct, as our study suggested, has been transformed into the yeast strain HF7c (Clontech)\n","LỖI: File không tồn tại: This construct, as our study suggested, has been transformed into the yeast strain HF7c (Clontech)\n","\n","Nhập đường dẫn file test Span AV: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/span_adaptation_vectors_train_gramvar/transform_1/sentence_7_ARG_2.pt\n","\n","--- Kết quả tìm kiếm cho: sentence_7_ARG_2.pt ---\n","Động từ: transform_1, Argument: ARG-2\n","\n","5 láng giềng gần nhất trong tập Train:\n","\n","1. Score: 1.0000\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-2\n","   Câu gốc: This construct, as our study suggested, has been transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_7_ARG_2.pt\n","\n","2. Score: 0.9953\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-2\n","   Câu gốc: This construct, as our study suggested, can be transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_1_ARG_2.pt\n","\n","3. Score: 0.9950\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-2\n","   Câu gốc: This construct, as our study suggested, will be transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_23_ARG_2.pt\n","\n","4. Score: 0.9947\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-2\n","   Câu gốc: This construct, as our study suggested, may be transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_19_ARG_2.pt\n","\n","5. Score: 0.9943\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-2\n","   Câu gốc: This construct, as our study suggested, is transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_17_ARG_2.pt\n","\n","Nhập đường dẫn file test Span AV: /content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep/span_adaptation_vectors_train_gramvar/transform_1/sentence_18_ARG_1.pt\n","\n","--- Kết quả tìm kiếm cho: sentence_18_ARG_1.pt ---\n","Động từ: transform_1, Argument: ARG-1\n","\n","5 láng giềng gần nhất trong tập Train:\n","\n","1. Score: 1.0000\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-1\n","   Câu gốc: This construct, as our study suggested, may be efficiently transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_18_ARG_1.pt\n","\n","2. Score: 0.9966\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-1\n","   Câu gốc: This construct, as our study suggested, can be efficiently transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_0_ARG_1.pt\n","\n","3. Score: 0.9963\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-1\n","   Câu gốc: This construct, as our study suggested, may be transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_19_ARG_1.pt\n","\n","4. Score: 0.9951\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-1\n","   Câu gốc: This construct, as our study suggested, will be efficiently transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_22_ARG_1.pt\n","\n","5. Score: 0.9947\n","   Nguồn: span_adaptation_vectors_train_gramvar / transform_1 / ARG-1\n","   Câu gốc: This construct, as our study suggested, can be transformed into the yeast strain HF7c (Clontech).\n","   File vector gốc: sentence_1_ARG_1.pt\n","\n","Đã dừng bởi người dùng.\n","\n","--- Kết thúc chương trình tìm kiếm ---\n"]}],"source":["# Import các thư viện cần thiết\n","import torch\n","import os\n","import json\n","import glob\n","from tqdm.auto import tqdm\n","import torch.nn.functional as F\n","import re\n","\n","# --- 1. CẤU HÌNH ---\n","K_NEIGHBORS = 5\n","NUM_LAYERS_TO_MATCH = 12\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Sử dụng thiết bị: {device}\")\n","\n","# --- THIẾT LẬP CÁC ĐƯỜNG DẪN ---\n","drive_base_path = '/content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep'\n","output_dir = os.path.join(drive_base_path, 'matching_results')\n","\n","# Đường dẫn đến file trọng số đã học\n","weights_file_path = os.path.join(output_dir, 'learned_layer_weights.pt')\n","\n","# Đường dẫn đến database đã lưu\n","db_cache_dir = os.path.join(drive_base_path, 'cached_databases')\n","db_vectors_file = os.path.join(db_cache_dir, 'combined_train_db_vectors.pt')\n","db_metadata_file = os.path.join(db_cache_dir, 'combined_train_db_metadata.json')\n","\n","# Đường dẫn đến thư mục dữ liệu gốc của tập TRAIN (để tra cứu text neighbor)\n","train_data_dir_gramvar = os.path.join(drive_base_path, 'Clean_Dataset/Corpus/Split_GramVar/Train')\n","train_data_dir_parave = os.path.join(drive_base_path, 'Clean_Dataset/Corpus/Split_ParaVE/Train')\n","train_data_dirs_map = {\n","    'span_adaptation_vectors_train_gramvar': train_data_dir_gramvar,\n","    'span_adaptation_vectors_train_parave': train_data_dir_parave,\n","    # Thêm các nguồn dataset khác nếu DB của bạn bao gồm chúng\n","}\n","\n","# Regex để trích xuất chỉ số câu\n","sentence_idx_pattern = re.compile(r\"sentence_(\\d+)_\")\n","\n","# --- 2. CÁC HÀM XỬ LÝ ---\n","\n","def find_k_nearest_neighbors_weighted(test_span_vectors, db_vectors, db_metadata, k, weights):\n","    \"\"\"Tìm kNN có trọng số.\"\"\"\n","    test_vectors_unsqueezed = test_span_vectors.unsqueeze(0)\n","    weights = weights.to(db_vectors.device)\n","    similarities_per_layer = F.cosine_similarity(test_vectors_unsqueezed, db_vectors, dim=2)\n","    weighted_scores = torch.sum(similarities_per_layer * weights, dim=1)\n","    top_k_scores, top_k_indices = torch.topk(weighted_scores, k)\n","\n","    neighbors = []\n","    for score, index in zip(top_k_scores, top_k_indices.cpu()):\n","        neighbor_info = db_metadata[index].copy()\n","        neighbor_info['score'] = score.item()\n","        neighbors.append(neighbor_info)\n","    return neighbors\n","\n","def get_sentence_text_from_original(verb_name, sentence_idx, source_dataset_name):\n","    \"\"\"Lấy text câu gốc của neighbor.\"\"\"\n","    original_data_dir = train_data_dirs_map.get(source_dataset_name)\n","    if not original_data_dir: return \"N/A (Nguồn không xác định)\"\n","\n","    original_data_path = os.path.join(original_data_dir, f\"{verb_name}_train_set.json\")\n","    try:\n","        # Tối ưu: Cache lại file json đã đọc nếu cần\n","        # (Trong ví dụ này, đọc lại mỗi lần cho đơn giản)\n","        with open(original_data_path, 'r', encoding='utf-8') as f:\n","            original_data = json.load(f)\n","            if sentence_idx < len(original_data):\n","                return original_data[sentence_idx].get('text', 'N/A')\n","            else: return \"N/A (Index lỗi)\"\n","    except Exception: return \"N/A (Lỗi đọc file)\"\n","\n","# --- 3. TẢI DỮ LIỆU CỐ ĐỊNH ---\n","try:\n","    print(\"--- Bước 1: Tải trọng số quan trọng của các lớp ---\")\n","    learned_weights = torch.load(weights_file_path, map_location=device)\n","    print(\" -> Tải trọng số thành công!\")\n","except Exception as e:\n","    print(f\"LỖI: Không thể tải file trọng số '{weights_file_path}': {e}\")\n","    exit()\n","\n","print(\"\\n--- Bước 2: Tải cơ sở dữ liệu Train ---\")\n","try:\n","    train_db_vectors = torch.load(db_vectors_file)\n","    with open(db_metadata_file, 'r', encoding='utf-8') as f:\n","        train_db_metadata = json.load(f)\n","    print(f\" -> Tải thành công DB với {len(train_db_metadata)} span.\")\n","    print(f\"Chuyển DB sang '{device}'...\")\n","    train_db_vectors = train_db_vectors.to(device)\n","    print(\" -> Chuyển thành công!\")\n","except Exception as e:\n","    print(f\"LỖI khi tải database: {e}.\")\n","    print(\"Vui lòng chạy lại kịch bản 'build_database.py' trước.\")\n","    exit()\n","\n","# --- 4. VÒNG LẶP TƯƠNG TÁC ---\n","print(\"\\n--- Bắt đầu chế độ tìm kiếm tương tác ---\")\n","print(\"Nhập đường dẫn đến file Span AV (.pt) của mẫu test bạn muốn tìm.\")\n","print(\"Nhấn Enter hoặc gõ 'quit' để thoát.\")\n","\n","while True:\n","    try:\n","        test_file_path = input(\"\\nNhập đường dẫn file test Span AV: \").strip()\n","        if not test_file_path or test_file_path.lower() == 'quit':\n","            break\n","\n","        if not os.path.exists(test_file_path):\n","            print(f\"LỖI: File không tồn tại: {test_file_path}\")\n","            continue\n","\n","        # Trích xuất thông tin từ tên file\n","        filename_parts = os.path.basename(test_file_path).replace('.pt', '').split('_')\n","        arg_label = f\"{filename_parts[-2]}-{filename_parts[-1]}\"\n","        verb_name = os.path.basename(os.path.dirname(test_file_path))\n","        match = sentence_idx_pattern.search(os.path.basename(test_file_path))\n","        if not match:\n","            print(\"LỖI: Tên file không đúng định dạng (không tìm thấy 'sentence_..._').\")\n","            continue\n","        sentence_idx = int(match.group(1))\n","\n","        # Tải vector test\n","        layers_data = torch.load(test_file_path, map_location='cpu')\n","        if not all(f'layer_{j+1}' in layers_data for j in range(NUM_LAYERS_TO_MATCH)):\n","            print(\"LỖI: File vector test không chứa đủ 12 lớp.\")\n","            continue\n","\n","        layer_vectors = [layers_data[f'layer_{j+1}'] for j in range(NUM_LAYERS_TO_MATCH)]\n","        test_span_vectors = torch.stack(layer_vectors).to(device)\n","\n","        # Tìm kiếm láng giềng\n","        neighbors = find_k_nearest_neighbors_weighted(\n","            test_span_vectors, train_db_vectors, train_db_metadata, K_NEIGHBORS, learned_weights\n","        )\n","\n","        # In kết quả\n","        print(f\"\\n--- Kết quả tìm kiếm cho: {os.path.basename(test_file_path)} ---\")\n","        print(f\"Động từ: {verb_name}, Argument: {arg_label}\")\n","\n","        # (Tùy chọn) In câu gốc của mẫu test nếu muốn\n","        # test_sentence_text = get_sentence_text_from_test(...) # Cần thêm hàm tương tự cho test\n","        # print(f\"Câu test gốc: {test_sentence_text}\")\n","\n","        print(f\"\\n{K_NEIGHBORS} láng giềng gần nhất trong tập Train:\")\n","        for rank, neighbor in enumerate(neighbors, 1):\n","            neighbor_verb = neighbor['verb_name']\n","            neighbor_file = neighbor['original_file']\n","            source_dataset = neighbor.get('source_dataset', 'N/A') # Lấy nguồn nếu có\n","\n","            neighbor_match = sentence_idx_pattern.search(neighbor_file)\n","            neighbor_text = \"N/A\"\n","            if neighbor_match:\n","                neighbor_idx = int(neighbor_match.group(1))\n","                neighbor_text = get_sentence_text_from_original(neighbor_verb, neighbor_idx, source_dataset)\n","\n","            print(f\"\\n{rank}. Score: {neighbor['score']:.4f}\")\n","            print(f\"   Nguồn: {source_dataset} / {neighbor_verb} / {neighbor['arg_label']}\")\n","            print(f\"   Câu gốc: {neighbor_text}\")\n","            print(f\"   File vector gốc: {neighbor_file}\")\n","\n","    except KeyboardInterrupt:\n","        print(\"\\nĐã dừng bởi người dùng.\")\n","        break\n","    except Exception as e:\n","        print(f\"\\nĐã xảy ra lỗi: {e}\")\n","\n","print(\"\\n--- Kết thúc chương trình tìm kiếm ---\")\n"]},{"cell_type":"markdown","source":["- **Thông số chính**\n","  - `K_NEIGHBORS = 5`\n","  - `NUM_LAYERS_TO_MATCH = 12`\n","  - Thiết bị: `cuda` nếu có, ngược lại `cpu`.\n"],"metadata":{"id":"5mEOV_SPd1we"}},{"cell_type":"markdown","source":["- **Lưu ý/khuyến nghị**\n","  - Tên file phải đúng mẫu: `sentence_<idx>_ARG_<k>.pt` để regex trích **index**.\n","  - Nếu DB lớn, lần đầu **load** sẽ tốn RAM; nên dùng **DB đã cache** như trên.\n","  - Bổ sung thêm vào `train_data_dirs_map` nếu metadata DB có nguồn khác.\n","  - Có thể thêm hàm phụ để in luôn **câu test** (tương tự phần tra cứu Train)."],"metadata":{"id":"iBvKRELgd2tR"}},{"cell_type":"code","source":[],"metadata":{"id":"07n-hoGud4Yu"},"execution_count":null,"outputs":[]}]}