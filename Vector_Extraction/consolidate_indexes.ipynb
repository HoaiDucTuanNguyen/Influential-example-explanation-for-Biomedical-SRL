{"cells":[{"cell_type":"markdown","source":["# Tạo **Index gộp** cho nhiều bộ dữ liệu"],"metadata":{"id":"4OPdxYUFfplm"}},{"cell_type":"markdown","metadata":{"id":"15574447"},"source":["- **Mục đích**\n","  - Hợp nhất **tất cả entries** từ nhiều thư mục nguồn (mỗi thư mục là *dataset + split*) thành **một file index duy nhất** cho từng bộ.\n","  - Mỗi entry ánh xạ `sentence_text` ↔ `vector_file_path` (vector đã **chuẩn hoá**) để phục vụ truy vấn/huấn luyện/đánh giá.\n"]},{"cell_type":"markdown","source":["- **Đầu vào**\n","  - Danh sách cấu hình `datasets_to_process` (mỗi phần tử là bộ 3 tham số):  \n","    `(<name>, <data_dir>, <vectors_dir>)`\n","    ```python\n","    [\n","      (\"finetuned_gramvar_train\",\n","        \".../Clean_Dataset/Corpus/Split_GramVar/Train\",\n","        \".../finetuned_train_vectors_normalized_gramvar\"),\n","      (\"finetuned_parave_train\",\n","        \".../Clean_Dataset/Corpus/Split_ParaVE/Train\",\n","        \".../finetuned_train_vectors_normalized_parave\"),\n","      # có thể bổ sung thêm pre-trained / val / test ...\n","    ]\n","    ```\n","  - Thư mục **dữ liệu gốc**: nhiều file JSON theo từng động từ, dạng  \n","    `*_train_set.json` → mỗi file là **list** các item có khoá `\"text\"`.\n","  - Thư mục **vector đã chuẩn hoá** theo động từ:  \n","    `<vectors_dir>/<verb_name>/sentence_<i>.pt`"],"metadata":{"id":"oqJ9-MJkgSeS"}},{"cell_type":"markdown","source":["- **Đầu ra**\n","  - Thư mục đích:  \n","    `.../consolidated_indexes/`\n","  - Với mỗi cấu hình `<name>` sinh **01 file**:\n","    ```\n","    <name>_consolidated_index.json\n","    ```\n","  - Nội dung file là **một danh sách (list)** các entry:\n","    ```json\n","    [\n","      {\n","        \"sentence_text\": \"Protein A interacts with protein B.\",\n","        \"verb_name\": \"interact\",\n","        \"vector_file_path\": \"/content/.../finetuned_train_vectors_normalized_gramvar/interact/sentence_0.pt\"\n","      },\n","      {\n","        \"sentence_text\": \"Complex C binds to DNA.\",\n","        \"verb_name\": \"bind\",\n","        \"vector_file_path\": \"/content/.../finetuned_train_vectors_normalized_gramvar/bind/sentence_1.pt\"\n","      }\n","    ]\n","    ```"],"metadata":{"id":"PrSkcRoLhE8y"}},{"cell_type":"markdown","source":["- **Quy trình**\n","  1. Với từng bộ trong `datasets_to_process`:\n","     - **Bỏ qua** nếu file gộp đã tồn tại.\n","     - **Quét** tất cả `*.json` trong `<data_dir>`.\n","     - **Suy ra** `verb_name` từ tên file: `*_train_set.json` → `<verb_name>`.\n","     - **Đọc** list câu từ khoá `\"text\"` (lọc rỗng).\n","     - **Ghép** đường dẫn vector tương ứng:  \n","       `<vectors_dir>/<verb_name>/sentence_<i>.pt`\n","     - **Ghi** toàn bộ entries vào `.../consolidated_indexes/<name>_consolidated_index.json`."],"metadata":{"id":"UFdTpis6hJh1"}},{"cell_type":"code","source":["# Import các thư viện cần thiết\n","import os\n","import json\n","import glob\n","\n","# THIẾT LẬP CÁC ĐƯỜNG DẪN\n","\n","# Đường dẫn thư mục gốc trên Google Drive\n","drive_base_path = '/content/drive/MyDrive/Colab Notebooks/Khoa_Luan_Tot_Nghiep'\n","\n","# DANH SÁCH CÁC BỘ DỮ LIỆU CẦN TẠO INDEX GỘP\n","# Mỗi mục là một tuple chứa: (tên định danh, đường dẫn dữ liệu gốc, đường dẫn vector tương ứng)\n","datasets_to_process = [\n","    (\n","        \"finetuned_gramvar_train\",\n","        os.path.join(drive_base_path, 'Clean_Dataset/Corpus/Split_GramVar/Train'),\n","        os.path.join(drive_base_path, 'finetuned_train_vectors_normalized_gramvar')\n","    ),\n","    (\n","        \"finetuned_parave_train\",\n","        os.path.join(drive_base_path, 'Clean_Dataset/Corpus/Split_ParaVE/Train'),\n","        os.path.join(drive_base_path, 'finetuned_train_vectors_normalized_parave')\n","    ),\n","]\n","\n","# Đường dẫn đến thư mục MỚI để lưu các file index đã gộp\n","output_dir = os.path.join(drive_base_path, 'consolidated_indexes')\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# THỰC THI CHƯƠNG TRÌNH TẠO INDEX GỘP\n","\n","if __name__ == \"__main__\":\n","    print(\"--- Bắt đầu quá trình tạo index gộp từ dữ liệu gốc ---\")\n","\n","    for name, data_dir, vectors_dir in datasets_to_process:\n","        output_file_path = os.path.join(output_dir, f\"{name}_consolidated_index.json\")\n","\n","        if os.path.exists(output_file_path):\n","            print(f\"File gộp '{os.path.basename(output_file_path)}' đã tồn tại. Bỏ qua.\")\n","            continue\n","\n","        print(f\"\\nĐang xử lý bộ dữ liệu: {name}\")\n","\n","        all_index_entries = []\n","        # Tìm tất cả các file .json trong thư mục dữ liệu gốc (ví dụ: .../Train)\n","        json_files = glob.glob(os.path.join(data_dir, '*.json'))\n","\n","        for json_file in json_files:\n","            # Lấy tên động từ\n","            base_name = os.path.basename(json_file)\n","            verb_name = \"_\".join(base_name.replace('_train_set.json', '').split('_'))\n","\n","            with open(json_file, 'r', encoding='utf-8') as f:\n","                data = json.load(f)\n","\n","            # Trích xuất các câu\n","            sentences = [item['text'] for item in data if 'text' in item and item['text'].strip()]\n","\n","            # Tạo các mục index\n","            for i, sentence_text in enumerate(sentences):\n","                vector_file_path = os.path.join(vectors_dir, verb_name, f\"sentence_{i}.pt\")\n","\n","                index_entry = {\n","                    \"sentence_text\": sentence_text,\n","                    \"verb_name\": verb_name,\n","                    \"vector_file_path\": vector_file_path\n","                }\n","                all_index_entries.append(index_entry)\n","\n","        # Lưu danh sách đã gộp vào một file duy nhất\n","        if all_index_entries:\n","            with open(output_file_path, 'w', encoding='utf-8') as f:\n","                json.dump(all_index_entries, f, indent=4, ensure_ascii=False)\n","            print(f\" -> Đã tạo index gộp với {len(all_index_entries)} mục và lưu thành công.\")\n","        else:\n","            print(f\" -> Không có dữ liệu để xử lý trong '{name}'.\")\n","\n","    print(\"\\n--- QUÁ TRÌNH TẠO INDEX GỘP ĐÃ HOÀN TẤT! ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BuacySd1J8RC","outputId":"0cc843e5-0a4c-4bc9-e0ed-8d82d0e7c6f2","executionInfo":{"status":"ok","timestamp":1760228540099,"user_tz":-420,"elapsed":60,"user":{"displayName":"Linh Bùi Thu","userId":"16647398495852939072"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Bắt đầu quá trình tạo index gộp từ dữ liệu gốc ---\n","File gộp 'finetuned_gramvar_train_consolidated_index.json' đã tồn tại. Bỏ qua.\n","File gộp 'finetuned_parave_train_consolidated_index.json' đã tồn tại. Bỏ qua.\n","\n","--- QUÁ TRÌNH TẠO INDEX GỘP ĐÃ HOÀN TẤT! ---\n"]}]},{"cell_type":"markdown","source":["- **Cấu trúc thư mục (minh hoạ)**\n","  ```bash\n","  .../Clean_Dataset/Corpus/Split_GramVar/Train/\n","  ├── begin_1_train_set.json\n","  ├── bind_2_train_set.json\n","  └── ...\n","\n","  .../finetuned_train_vectors_normalized_gramvar/\n","  ├── begin_1/\n","  │   ├── sentence_0.pt\n","  │   ├── sentence_1.pt\n","  │   └── ...\n","  ├── bind_2/\n","  │   ├── sentence_0.pt\n","  │   └── ...\n","  └── ...\n","\n","  .../consolidated_indexes/\n","  ├── finetuned_gramvar_train_consolidated_index.json\n","  └── finetuned_parave_train_consolidated_index.json"],"metadata":{"id":"7jDVzlRphK0U"}},{"cell_type":"code","source":[],"metadata":{"id":"cXAX4M-HrI7X"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}