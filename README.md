# Influential-example-explanation-for-Biomedical-SRL
ATaVEE is a post-hoc framework for span-level training-data attribution that explains an NLP model’s predictions by surfacing the training spans most responsible for the current decision and indicating whether each retrieved span supports or harms the prediction. It is designed for structured prediction settings where outputs are naturally span-based (e.g., SRL, NER), and where “similar examples” in a generic embedding space may be informative but not necessarily aligned with what the model actually learned during task fine-tuning.
The core idea is to perform retrieval in a fine-tuning–aware adaptation space rather than the model’s final hidden space. ATaVEE constructs Activation Task Vectors (ATVs) that capture the fine-tuning–induced change in activations, helping separate task-specific learning from broader pretraining priors. To make ATV comparisons stable, ATaVEE mitigates representational drift with normalization (removing trivial mean/scale shifts) and orthogonal Procrustes alignment (reducing geometric rotations between pretrained and fine-tuned activation spaces). It then builds span-level ATVs, retrieves influential training spans using covariance-aware Mahalanobis matching, and ranks neighbors by how closely their adaptation signatures align with the test span’s.
Beyond retrieval, ATaVEE provides an explicit help–harm polarity for each retrieved example through an activation-space counterfactual intervention. Instead of retraining or perturbing parameters, ATaVEE attenuates the retrieved span’s fine-tuning signal in activation space and measures the resulting decision-margin change, yielding a polarity score that indicates whether the span pushes the model toward the correct label or toward competitors.
